{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdij5hoIr9B8mEfobcVzH8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Umaraslam66/Rail_DRL/blob/main/TrainRL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXOhV-7hJBz6"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "''''\n",
        "This class defines the Train schedule environments and the methods used\n",
        "The logics of trains moving will be added in\n",
        "''''\n",
        "class TrainSchedulingEnvironment(gym.Env):\n",
        "    def __init__(self, initial_timetable):\n",
        "        super(TrainSchedulingEnvironment, self).__init__()\n",
        "\n",
        "        # Defining action and observation space\n",
        "        self.action_space = spaces.Discrete(num_actions)\n",
        "        self.observation_space = spaces.Dict({\n",
        "            \"timetable\": spaces.Discrete(num_time_intervals),  # Discrete time intervals based on the train movements\n",
        "            \"train_positions\": spaces.Box(low=0, high=max_track_length, shape=(num_trains,), dtype=np.float32),\n",
        "            \"train_speeds\": spaces.Box(low=0, high=max_speed, shape=(num_trains,), dtype=np.float32),\n",
        "            \"train_dwell_time\": spaces.Box(low=0, high=max_dwell_time, shape=(num_trains,), dtype=np.float32)\n",
        "            \"train_running_time\": spaces.Box(low=0, high=max_running_time, shape=(num_trains,), dtype=np.float32)\n",
        "            # Adding some other attributes maybe TBD\n",
        "        })\n",
        "\n",
        "        self.current_timetable = initial_timetable #initila timetable with some supplement\n",
        "        self.current_train_positions = np.zeros(num_trains)  # Initial positions\n",
        "        self.current_train_speeds = np.zeros(num_trains)  # Initial speeds\n",
        "\n",
        "    def step(self, action):\n",
        "        # Implement the logic for taking an action and updating the environment\n",
        "        # Calculate new train positions and speeds based on the action\n",
        "        new_train_positions = self.calculate_new_positions(action)\n",
        "        new_train_speeds = self.calculate_new_speeds(action)\n",
        "\n",
        "        # Update the state\n",
        "        self.current_train_positions = new_train_positions\n",
        "        self.current_train_speeds = new_train_speeds\n",
        "\n",
        "        # Calculate reward based on the updated state\n",
        "        reward = self.calculate_reward()\n",
        "\n",
        "        # Determine if the episode is done (e.g., based on time intervals or specific conditions)\n",
        "        done = self.is_episode_done()\n",
        "\n",
        "        # Return the new state, reward, and whether the episode is done\n",
        "        new_state = self.get_state()\n",
        "        return new_state, reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        # Reset the environment to the initial state\n",
        "        self.current_train_positions = np.zeros(num_trains)\n",
        "        self.current_train_speeds = np.zeros(num_trains)\n",
        "        return self.get_state()\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        # TBD Train states, movements, etc.\n",
        "        pass\n",
        "\n",
        "    def get_state(self):\n",
        "      # Environmentâ€™s state into an observation\n",
        "        state = {\n",
        "            \"timetable\": self.current_timetable,\n",
        "            \"train_positions\": self.current_train_positions,\n",
        "            \"train_speeds\": self.current_train_speeds,\n",
        "            # Have to add some other attributes TBD\n",
        "        }\n",
        "        return state\n",
        "\n",
        "    def calculate_new_positions(self, action):\n",
        "      ''''\n",
        "      Not sure if we can find out the positions of the trains as the idea is\n",
        "      not following the real time operation setting. But can be figured out with\n",
        "      the speeds based on section lengths\n",
        "      ''''\n",
        "        # new train positions based on the chosen action\n",
        "        pass\n",
        "\n",
        "    def calculate_new_speeds(self, action):\n",
        "      ''''\n",
        "      Agent has the control over the speeds of trains while keeping it in range\n",
        "      of maximum speeds and other than that speed will be deciding factor for\n",
        "      figuring out the current and new poistions of the train give the accelerations\n",
        "      ''''\n",
        "        # new train speeds/running times based on the chosen action (First State Vector)\n",
        "        pass\n",
        "\n",
        "    def calculate_new_dwell(self, action):\n",
        "      ''''\n",
        "      Have to decide if the new dwell also includes the waiting times on the\n",
        "      station tracks to make way for the coming priority trains or will that\n",
        "      be a new method here\n",
        "      ''''\n",
        "        pass\n",
        "\n",
        "    def calculate_reward(self):\n",
        "      ''''\n",
        "      Reward structure needs to be decided, it could be sparse\n",
        "      as the agent only gets the reward when all trains traverse the\n",
        "      section conflict free and with no huge delays\n",
        "      ''''\n",
        "        pass\n",
        "\n",
        "    def is_episode_done(self):\n",
        "        # Episode completion\n",
        "        pass\n",
        "\n",
        "# initialization\n",
        "num_actions =   # number of actions\n",
        "num_time_intervals =   # number of time intervals in the timetable\n",
        "num_trains =   # number of trains\n",
        "max_track_length =   #  maximum track length\n",
        "max_speed =   # maximum speed\n",
        "train_running_time = # Train running time\n",
        "train_dwell_time = # Dwell times\n",
        "#Stopping Patterns\n",
        "''''\n",
        "Initial timetable is an important attribute and can be added as a dataframe\n",
        "to initialize the class\n",
        "''''\n",
        "initial_timetable = {}  # initial timetable data\n",
        "\n",
        "env = TrainSchedulingEnvironment(initial_timetable)"
      ]
    }
  ]
}